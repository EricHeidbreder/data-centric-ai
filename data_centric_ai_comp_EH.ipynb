{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<a href=\"https://colab.research.google.com/github/EricHeidbreder/data-centric-ai/blob/eric_h/data_centric_ai_comp_copy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ],
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "source": [
        "\r\n",
        "import requests\r\n",
        "import tarfile\r\n",
        "import io\r\n",
        "import numpy as np\r\n",
        "from PIL import Image, ImageTk\r\n",
        "from matplotlib import pyplot as plt\r\n",
        "import pandas as pd\r\n",
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\r\n",
        "from tensorflow.python.keras.preprocessing import dataset_utils\r\n",
        "import os\r\n",
        "import tensorflow as tf\r\n",
        "from tensorflow import keras\r\n",
        "import json\r\n",
        "import sys\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "# from google.colab.patches import cv2_imshow\r\n",
        "\r\n",
        "import shutil\r\n",
        "import random"
      ],
      "outputs": [],
      "metadata": {
        "id": "L965aAYLKcWv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "source": [
        "# Give you a fresh start on preprocessed data\r\n",
        "shutil.rmtree('./data_preprocessed', ignore_errors=True)\r\n",
        "\r\n",
        "# Building the preprocessing folder structure\r\n",
        "os.mkdir('./data_preprocessed')\r\n",
        "os.mkdir('./data_preprocessed/train')\r\n",
        "os.mkdir('./data_preprocessed/val')\r\n",
        "for num in ['i', 'ii', 'iii', 'iv', 'v', 'vi', 'vii', 'viii', 'ix', 'x']:\r\n",
        "    os.mkdir(f'./data_preprocessed/train/{num}')\r\n",
        "    os.mkdir(f'./data_preprocessed/val/{num}')"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "source": [
        "# get the test data into its own folder\r\n",
        "\r\n",
        "test_path = './data_preprocessed/test'\r\n",
        "\r\n",
        "tar_file = tarfile.open('./label_book.tar.gz')\r\n",
        "tar_file.extractall(test_path)\r\n",
        "tar_file.close()\r\n",
        "\r\n",
        "orig_base_path = os.path.join(test_path, 'label_book')\r\n",
        "for folder in os.listdir(orig_base_path):\r\n",
        "    if folder != '.DS_Store':\r\n",
        "        orig_path = os.path.join(orig_base_path, folder)\r\n",
        "        new_path = test_path\r\n",
        "        shutil.move(orig_path, new_path)\r\n",
        "\r\n",
        "shutil.rmtree(orig_base_path)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "source": [
        "train_datagen = ImageDataGenerator(rotation_range=20,\r\n",
        "                                   width_shift_range=0.2,\r\n",
        "                                   height_shift_range=0.2,\r\n",
        "                                   rescale=1/255,\r\n",
        "                                   shear_range=0.2,\r\n",
        "                                   zoom_range=0.2,\r\n",
        "                                   horizontal_flip=False)\r\n",
        "\r\n",
        "valid_datagen = ImageDataGenerator(rotation_range=20,\r\n",
        "                                   width_shift_range=0.2,\r\n",
        "                                   height_shift_range=0.2,\r\n",
        "                                   rescale=1/255,\r\n",
        "                                   shear_range=0.2,\r\n",
        "                                   zoom_range=0.2,\r\n",
        "                                   horizontal_flip=False)"
      ],
      "outputs": [],
      "metadata": {
        "id": "yGI7F9v5LZyh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "source": [
        "batch_size = len(os.listdir('.\\\\data_sorted\\\\train\\\\ii'))\r\n",
        "batch_size"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GOLzY53-WT9n",
        "outputId": "9f5d4af2-2b7c-40ae-c325-64060404f9d8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "source": [
        "data_sorted_path = '.\\\\data_sorted_copy'\r\n",
        "class_folders = os.listdir(data_sorted_path)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "for folder in class_folders:\r\n",
        "  # Don't do this in the test folder\r\n",
        "  if folder not in [\r\n",
        "    'test',\r\n",
        "    '.DS_Store',\r\n",
        "    # TODO: remove val after subgroups are added to that folder\r\n",
        "    'val'\r\n",
        "  ]:\r\n",
        "    class_folders = os.listdir(os.path.join(data_sorted_path, folder))\r\n",
        "  else:\r\n",
        "    continue\r\n",
        "\r\n",
        "  # Iterates through the subfolders in each class. \r\n",
        "  # Makes sure there are an equal number of items from each subgroup within the classes by randomly sampling the smaller subgroups\r\n",
        "  for class_folder in class_folders:\r\n",
        "    \r\n",
        "    # Gather initial information about the class path and the number of subgroups\r\n",
        "    if class_folder not in ['.DS_Store', 'junk_vals']:\r\n",
        "    # if class_folder == 'i':\r\n",
        "      class_path = os.path.join(data_sorted_path, folder, class_folder)\r\n",
        "      class_subgroups = os.listdir(class_path)\r\n",
        "      max_subgroup_len = 0\r\n",
        "\r\n",
        "      # Need to get the max number of files in a subgroup folder, so we can get them all to match later\r\n",
        "      for class_folder_subgroup in class_subgroups:\r\n",
        "        max_subgroup_len = max(len(os.listdir(os.path.join(data_sorted_path, folder, class_folder, class_folder_subgroup))), max_subgroup_len)\r\n",
        "\r\n",
        "      # Get the subgroup path (example i_lowercase, i_ruled, etc.)\r\n",
        "      for class_folder_subgroup in class_subgroups:\r\n",
        "        class_subgroup_path = os.path.join(data_sorted_path, folder, class_folder, class_folder_subgroup)\r\n",
        "\r\n",
        "        # If the subgroup isn't the max length, determine how many copies we need to make to get it to match\r\n",
        "        if len(os.listdir(class_subgroup_path)) < max_subgroup_len:\r\n",
        "          subgroup_images = os.listdir(class_subgroup_path)\r\n",
        "          num_subgroup_images = len(subgroup_images)\r\n",
        "          num_copies_to_make = max_subgroup_len - num_subgroup_images\r\n",
        "\r\n",
        "          # Make the copies using random sampling of the existing images\r\n",
        "          for i in range(num_copies_to_make):\r\n",
        "            random_image = subgroup_images[random.randint(0, num_subgroup_images - 1)]\r\n",
        "            shutil.copyfile(os.path.join(class_subgroup_path, random_image), class_subgroup_path+f'/copy_{i}_{random_image}')\r\n",
        "\r\n",
        "    else:\r\n",
        "        continue"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "source": [
        "class_names=[\"i\", \"ii\", \"iii\", \"iv\", \"v\", \"vi\", \"vii\", \"viii\", \"ix\", \"x\"]\r\n",
        "\r\n",
        "for class_name in class_names:\r\n",
        "  train_generator = train_datagen.flow_from_directory(\r\n",
        "    './data_sorted_copy/train',\r\n",
        "    target_size=(32,32),\r\n",
        "    batch_size=500,\r\n",
        "    classes=[class_name],\r\n",
        "    save_to_dir='./data_preprocessed/train/'+class_name,\r\n",
        "    save_prefix='aug',\r\n",
        "    shuffle=True\r\n",
        "  )\r\n",
        "  batch = next(train_generator)\r\n",
        " \r\n",
        "for class_name in class_names:\r\n",
        "  batch_size = len([f for f in os.listdir('./data_sorted_copy/val/'+ class_name) if os.path.isfile(os.path.join('./data_sorted_copy/val/' + class_name, f))])\r\n",
        "  validation_generator = valid_datagen.flow_from_directory(\r\n",
        "        './data_sorted_copy/val',\r\n",
        "        target_size=(32, 32),\r\n",
        "        class_mode='categorical',\r\n",
        "        classes=[class_name],\r\n",
        "        batch_size=batch_size,\r\n",
        "        shuffle=False,\r\n",
        "        save_to_dir='./data_preprocessed/val/'+class_name)  \r\n",
        "  batch = next(validation_generator)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 513 images belonging to 1 classes.\n",
            "Found 270 images belonging to 1 classes.\n",
            "Found 258 images belonging to 1 classes.\n",
            "Found 549 images belonging to 1 classes.\n",
            "Found 339 images belonging to 1 classes.\n",
            "Found 210 images belonging to 1 classes.\n",
            "Found 256 images belonging to 1 classes.\n",
            "Found 375 images belonging to 1 classes.\n",
            "Found 312 images belonging to 1 classes.\n",
            "Found 345 images belonging to 1 classes.\n",
            "Found 82 images belonging to 1 classes.\n",
            "Found 82 images belonging to 1 classes.\n",
            "Found 79 images belonging to 1 classes.\n",
            "Found 84 images belonging to 1 classes.\n",
            "Found 82 images belonging to 1 classes.\n",
            "Found 82 images belonging to 1 classes.\n",
            "Found 77 images belonging to 1 classes.\n",
            "Found 83 images belonging to 1 classes.\n",
            "Found 81 images belonging to 1 classes.\n",
            "Found 81 images belonging to 1 classes.\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WWOantahLe7c",
        "outputId": "7b536468-8196-4358-f23d-5a9cee06f134"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "source": [
        "directory = \"./data_preprocessed\"\r\n",
        "user_data = directory + \"/train\"\r\n",
        "valid_data = directory + \"/val\"\r\n",
        "test_data = directory + \"/test\" # this can be the label book, or any other test set you create\r\n",
        "\r\n",
        "### DO NOT MODIFY BELOW THIS LINE, THIS IS THE FIXED MODEL ###\r\n",
        "batch_size = 8\r\n",
        "tf.random.set_seed(123)\r\n",
        "\r\n",
        "\r\n",
        "if __name__ == \"__main__\":\r\n",
        "    train = tf.keras.preprocessing.image_dataset_from_directory(\r\n",
        "        user_data,# + '/train',\r\n",
        "        labels=\"inferred\",\r\n",
        "        label_mode=\"categorical\",\r\n",
        "        class_names=[\"i\", \"ii\", \"iii\", \"iv\", \"v\", \"vi\", \"vii\", \"viii\", \"ix\", \"x\"],\r\n",
        "        shuffle=True,\r\n",
        "        seed=123,\r\n",
        "        batch_size=batch_size,\r\n",
        "        image_size=(32, 32),\r\n",
        "    )\r\n",
        "\r\n",
        "    valid = tf.keras.preprocessing.image_dataset_from_directory(\r\n",
        "        valid_data,# + '/val',\r\n",
        "        labels=\"inferred\",\r\n",
        "        label_mode=\"categorical\",\r\n",
        "        class_names=[\"i\", \"ii\", \"iii\", \"iv\", \"v\", \"vi\", \"vii\", \"viii\", \"ix\", \"x\"],\r\n",
        "        shuffle=True,\r\n",
        "        seed=123,\r\n",
        "        batch_size=batch_size,\r\n",
        "        image_size=(32, 32),\r\n",
        "    )\r\n",
        "\r\n",
        "    total_length = ((train.cardinality() + valid.cardinality()) * batch_size).numpy()\r\n",
        "    if total_length > 10_000:\r\n",
        "        print(f\"Dataset size larger than 10,000. Got {total_length} examples\")\r\n",
        "        sys.exit()\r\n",
        "\r\n",
        "    test = tf.keras.preprocessing.image_dataset_from_directory(\r\n",
        "        test_data,\r\n",
        "        labels=\"inferred\",\r\n",
        "        label_mode=\"categorical\",\r\n",
        "        class_names=[\"i\", \"ii\", \"iii\", \"iv\", \"v\", \"vi\", \"vii\", \"viii\", \"ix\", \"x\"],\r\n",
        "        shuffle=False,\r\n",
        "        seed=123,\r\n",
        "        batch_size=batch_size,\r\n",
        "        image_size=(32, 32),\r\n",
        "    )\r\n",
        "\r\n",
        "    base_model = tf.keras.applications.ResNet50(\r\n",
        "        input_shape=(32, 32, 3),\r\n",
        "        include_top=False,\r\n",
        "        weights=None,\r\n",
        "    )\r\n",
        "    base_model = tf.keras.Model(\r\n",
        "        base_model.inputs, outputs=[base_model.get_layer(\"conv2_block3_out\").output]\r\n",
        "    )\r\n",
        "\r\n",
        "    inputs = tf.keras.Input(shape=(32, 32, 3))\r\n",
        "    x = tf.keras.applications.resnet.preprocess_input(inputs)\r\n",
        "    x = base_model(x)\r\n",
        "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\r\n",
        "    x = tf.keras.layers.Dense(10)(x)\r\n",
        "    model = tf.keras.Model(inputs, x)\r\n",
        "\r\n",
        "    model.compile(\r\n",
        "        optimizer=tf.keras.optimizers.Adam(lr=0.0001),\r\n",
        "        loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\r\n",
        "        metrics=[\"accuracy\"],\r\n",
        "    )\r\n",
        "    model.summary()\r\n",
        "    loss_0, acc_0 = model.evaluate(valid)\r\n",
        "    print(f\"loss {loss_0}, acc {acc_0}\")\r\n",
        "\r\n",
        "    checkpoint = tf.keras.callbacks.ModelCheckpoint(\r\n",
        "        \"best_model\",\r\n",
        "        monitor=\"val_accuracy\",\r\n",
        "        mode=\"max\",\r\n",
        "        save_best_only=True,\r\n",
        "        save_weights_only=True,\r\n",
        "    )\r\n",
        "\r\n",
        "    history = model.fit(\r\n",
        "        train,\r\n",
        "        validation_data=valid,\r\n",
        "        epochs=100,\r\n",
        "        callbacks=[checkpoint],\r\n",
        "    )\r\n",
        "\r\n",
        "    model.load_weights(\"best_model\")\r\n",
        "\r\n",
        "    loss, acc = model.evaluate(valid)\r\n",
        "    print(f\"final loss {loss}, final acc {acc}\")\r\n",
        "\r\n",
        "    test_loss, test_acc = model.evaluate(test)\r\n",
        "    print(f\"test loss {test_loss}, test acc {test_acc}\")\r\n",
        "\r\n",
        "   "
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3365 files belonging to 10 classes.\n",
            "Found 813 files belonging to 10 classes.\n",
            "Found 52 files belonging to 10 classes.\n",
            "Model: \"model_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_6 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
            "_________________________________________________________________\n",
            "tf.__operators__.getitem_2 ( (None, 32, 32, 3)         0         \n",
            "_________________________________________________________________\n",
            "tf.nn.bias_add_2 (TFOpLambda (None, 32, 32, 3)         0         \n",
            "_________________________________________________________________\n",
            "model_4 (Functional)         (None, 8, 8, 256)         229760    \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_2 ( (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                2570      \n",
            "=================================================================\n",
            "Total params: 232,330\n",
            "Trainable params: 229,386\n",
            "Non-trainable params: 2,944\n",
            "_________________________________________________________________\n",
            "102/102 [==============================] - 3s 26ms/step - loss: 29.4582 - accuracy: 0.1049\n",
            "loss 29.597599029541016, acc 0.09471094608306885\n",
            "Epoch 1/100\n",
            "421/421 [==============================] - 15s 33ms/step - loss: 2.1635 - accuracy: 0.2348 - val_loss: 2.6851 - val_accuracy: 0.0984\n",
            "Epoch 2/100\n",
            "421/421 [==============================] - 5s 11ms/step - loss: 1.8654 - accuracy: 0.3542 - val_loss: 2.4741 - val_accuracy: 0.1587\n",
            "Epoch 3/100\n",
            "421/421 [==============================] - 5s 11ms/step - loss: 1.7149 - accuracy: 0.4045 - val_loss: 2.1568 - val_accuracy: 0.2694\n",
            "Epoch 4/100\n",
            "421/421 [==============================] - 5s 11ms/step - loss: 1.6013 - accuracy: 0.4505 - val_loss: 2.1752 - val_accuracy: 0.2718\n",
            "Epoch 5/100\n",
            "421/421 [==============================] - 5s 11ms/step - loss: 1.4893 - accuracy: 0.4948 - val_loss: 2.0904 - val_accuracy: 0.3087\n",
            "Epoch 6/100\n",
            "421/421 [==============================] - 5s 11ms/step - loss: 1.3985 - accuracy: 0.5180 - val_loss: 2.2195 - val_accuracy: 0.2608\n",
            "Epoch 7/100\n",
            "421/421 [==============================] - 5s 11ms/step - loss: 1.2975 - accuracy: 0.5608 - val_loss: 2.0064 - val_accuracy: 0.3309\n",
            "Epoch 8/100\n",
            "421/421 [==============================] - 5s 11ms/step - loss: 1.2114 - accuracy: 0.5899 - val_loss: 1.9094 - val_accuracy: 0.3592\n",
            "Epoch 9/100\n",
            "421/421 [==============================] - 5s 11ms/step - loss: 1.1053 - accuracy: 0.6377 - val_loss: 2.2575 - val_accuracy: 0.3235\n",
            "Epoch 10/100\n",
            "421/421 [==============================] - 5s 11ms/step - loss: 1.0358 - accuracy: 0.6484 - val_loss: 1.9077 - val_accuracy: 0.3469\n",
            "Epoch 11/100\n",
            "421/421 [==============================] - 5s 11ms/step - loss: 0.9507 - accuracy: 0.6877 - val_loss: 2.0579 - val_accuracy: 0.3149\n",
            "Epoch 12/100\n",
            "421/421 [==============================] - 5s 11ms/step - loss: 0.8669 - accuracy: 0.7308 - val_loss: 2.4745 - val_accuracy: 0.2386\n",
            "Epoch 13/100\n",
            "421/421 [==============================] - 5s 11ms/step - loss: 0.8029 - accuracy: 0.7421 - val_loss: 2.1024 - val_accuracy: 0.3456\n",
            "Epoch 14/100\n",
            "421/421 [==============================] - 5s 11ms/step - loss: 0.7292 - accuracy: 0.7691 - val_loss: 2.4675 - val_accuracy: 0.2891\n",
            "Epoch 15/100\n",
            "421/421 [==============================] - 5s 11ms/step - loss: 0.6493 - accuracy: 0.8039 - val_loss: 2.2389 - val_accuracy: 0.2755\n",
            "Epoch 16/100\n",
            "421/421 [==============================] - 5s 11ms/step - loss: 0.6019 - accuracy: 0.8175 - val_loss: 2.1250 - val_accuracy: 0.3001\n",
            "Epoch 17/100\n",
            "421/421 [==============================] - 5s 11ms/step - loss: 0.5430 - accuracy: 0.8371 - val_loss: 2.5406 - val_accuracy: 0.3001\n",
            "Epoch 18/100\n",
            "421/421 [==============================] - 5s 11ms/step - loss: 0.5020 - accuracy: 0.8547 - val_loss: 2.2744 - val_accuracy: 0.3173\n",
            "Epoch 19/100\n",
            "421/421 [==============================] - 5s 11ms/step - loss: 0.4439 - accuracy: 0.8728 - val_loss: 2.1828 - val_accuracy: 0.3186\n",
            "Epoch 20/100\n",
            "421/421 [==============================] - 5s 11ms/step - loss: 0.4065 - accuracy: 0.8883 - val_loss: 2.1017 - val_accuracy: 0.3862\n",
            "Epoch 21/100\n",
            "421/421 [==============================] - 5s 11ms/step - loss: 0.3692 - accuracy: 0.8984 - val_loss: 2.2505 - val_accuracy: 0.3604\n",
            "Epoch 22/100\n",
            "421/421 [==============================] - 5s 11ms/step - loss: 0.3629 - accuracy: 0.8963 - val_loss: 2.3937 - val_accuracy: 0.3604\n",
            "Epoch 23/100\n",
            "421/421 [==============================] - 5s 11ms/step - loss: 0.3086 - accuracy: 0.9192 - val_loss: 2.4049 - val_accuracy: 0.3506\n",
            "Epoch 24/100\n",
            "421/421 [==============================] - 5s 11ms/step - loss: 0.2964 - accuracy: 0.9239 - val_loss: 3.1595 - val_accuracy: 0.2657\n",
            "Epoch 25/100\n",
            "421/421 [==============================] - 5s 11ms/step - loss: 0.2797 - accuracy: 0.9221 - val_loss: 2.7045 - val_accuracy: 0.3198\n",
            "Epoch 26/100\n",
            "421/421 [==============================] - 5s 11ms/step - loss: 0.2656 - accuracy: 0.9319 - val_loss: 2.6082 - val_accuracy: 0.3419\n",
            "Epoch 27/100\n",
            "421/421 [==============================] - 5s 11ms/step - loss: 0.2241 - accuracy: 0.9444 - val_loss: 2.6489 - val_accuracy: 0.3444\n",
            "Epoch 28/100\n",
            "421/421 [==============================] - 5s 11ms/step - loss: 0.2002 - accuracy: 0.9501 - val_loss: 2.7375 - val_accuracy: 0.3223\n",
            "Epoch 29/100\n",
            "421/421 [==============================] - 5s 11ms/step - loss: 0.2067 - accuracy: 0.9462 - val_loss: 2.7290 - val_accuracy: 0.3321\n",
            "Epoch 30/100\n",
            "421/421 [==============================] - 5s 11ms/step - loss: 0.1977 - accuracy: 0.9480 - val_loss: 3.3581 - val_accuracy: 0.2817\n",
            "Epoch 31/100\n",
            "421/421 [==============================] - 5s 11ms/step - loss: 0.1784 - accuracy: 0.9542 - val_loss: 2.8534 - val_accuracy: 0.3137\n",
            "Epoch 32/100\n",
            "421/421 [==============================] - 5s 11ms/step - loss: 0.1719 - accuracy: 0.9557 - val_loss: 3.0592 - val_accuracy: 0.3456\n",
            "Epoch 33/100\n",
            "421/421 [==============================] - 5s 11ms/step - loss: 0.1748 - accuracy: 0.9516 - val_loss: 2.8735 - val_accuracy: 0.3469\n",
            "Epoch 34/100\n",
            "421/421 [==============================] - 5s 11ms/step - loss: 0.1863 - accuracy: 0.9459 - val_loss: 3.2691 - val_accuracy: 0.2657\n",
            "Epoch 35/100\n",
            "421/421 [==============================] - 5s 12ms/step - loss: 0.1633 - accuracy: 0.9566 - val_loss: 3.0038 - val_accuracy: 0.3370\n",
            "Epoch 36/100\n",
            "421/421 [==============================] - 5s 11ms/step - loss: 0.1606 - accuracy: 0.9623 - val_loss: 2.9559 - val_accuracy: 0.3260\n",
            "Epoch 37/100\n",
            "421/421 [==============================] - 5s 11ms/step - loss: 0.1579 - accuracy: 0.9557 - val_loss: 2.9722 - val_accuracy: 0.3026\n",
            "Epoch 38/100\n",
            "421/421 [==============================] - 5s 11ms/step - loss: 0.1389 - accuracy: 0.9629 - val_loss: 2.8391 - val_accuracy: 0.3346\n",
            "Epoch 39/100\n",
            "421/421 [==============================] - 5s 12ms/step - loss: 0.1723 - accuracy: 0.9498 - val_loss: 3.7357 - val_accuracy: 0.2854\n",
            "Epoch 40/100\n",
            "421/421 [==============================] - 5s 12ms/step - loss: 0.1180 - accuracy: 0.9709 - val_loss: 3.7940 - val_accuracy: 0.3014\n",
            "Epoch 41/100\n",
            "421/421 [==============================] - 5s 12ms/step - loss: 0.1298 - accuracy: 0.9608 - val_loss: 3.9148 - val_accuracy: 0.2534\n",
            "Epoch 42/100\n",
            "421/421 [==============================] - 5s 13ms/step - loss: 0.1052 - accuracy: 0.9724 - val_loss: 3.5093 - val_accuracy: 0.3432\n",
            "Epoch 43/100\n",
            "421/421 [==============================] - 6s 14ms/step - loss: 0.1216 - accuracy: 0.9688 - val_loss: 3.6845 - val_accuracy: 0.3137\n",
            "Epoch 44/100\n",
            "421/421 [==============================] - 5s 12ms/step - loss: 0.1033 - accuracy: 0.9747 - val_loss: 4.2436 - val_accuracy: 0.2977\n",
            "Epoch 45/100\n",
            "421/421 [==============================] - 5s 12ms/step - loss: 0.1357 - accuracy: 0.9634 - val_loss: 3.5139 - val_accuracy: 0.3296\n",
            "Epoch 46/100\n",
            "421/421 [==============================] - 5s 12ms/step - loss: 0.1391 - accuracy: 0.9611 - val_loss: 3.1510 - val_accuracy: 0.3530\n",
            "Epoch 47/100\n",
            "421/421 [==============================] - 5s 12ms/step - loss: 0.1105 - accuracy: 0.9685 - val_loss: 3.0305 - val_accuracy: 0.3493\n",
            "Epoch 48/100\n",
            "421/421 [==============================] - 5s 12ms/step - loss: 0.0976 - accuracy: 0.9744 - val_loss: 2.9837 - val_accuracy: 0.3653\n",
            "Epoch 49/100\n",
            "421/421 [==============================] - 5s 12ms/step - loss: 0.1292 - accuracy: 0.9614 - val_loss: 4.7923 - val_accuracy: 0.2202\n",
            "Epoch 50/100\n",
            "421/421 [==============================] - 5s 12ms/step - loss: 0.1190 - accuracy: 0.9667 - val_loss: 5.7824 - val_accuracy: 0.2276\n",
            "Epoch 51/100\n",
            "421/421 [==============================] - 5s 12ms/step - loss: 0.1208 - accuracy: 0.9682 - val_loss: 3.1894 - val_accuracy: 0.3579\n",
            "Epoch 52/100\n",
            "421/421 [==============================] - 5s 12ms/step - loss: 0.1117 - accuracy: 0.9661 - val_loss: 2.8625 - val_accuracy: 0.3555\n",
            "Epoch 53/100\n",
            "421/421 [==============================] - 5s 12ms/step - loss: 0.0858 - accuracy: 0.9801 - val_loss: 3.3266 - val_accuracy: 0.3186\n",
            "Epoch 54/100\n",
            "421/421 [==============================] - 5s 12ms/step - loss: 0.0908 - accuracy: 0.9765 - val_loss: 3.4981 - val_accuracy: 0.3432\n",
            "Epoch 55/100\n",
            "421/421 [==============================] - 5s 12ms/step - loss: 0.1043 - accuracy: 0.9685 - val_loss: 3.2542 - val_accuracy: 0.3272\n",
            "Epoch 56/100\n",
            "421/421 [==============================] - 5s 12ms/step - loss: 0.0951 - accuracy: 0.9750 - val_loss: 2.9308 - val_accuracy: 0.3592\n",
            "Epoch 57/100\n",
            "421/421 [==============================] - 5s 12ms/step - loss: 0.0788 - accuracy: 0.9804 - val_loss: 3.7960 - val_accuracy: 0.3173\n",
            "Epoch 58/100\n",
            "421/421 [==============================] - 5s 11ms/step - loss: 0.1085 - accuracy: 0.9685 - val_loss: 3.3515 - val_accuracy: 0.3383\n",
            "Epoch 59/100\n",
            "421/421 [==============================] - 5s 11ms/step - loss: 0.0971 - accuracy: 0.9741 - val_loss: 3.1767 - val_accuracy: 0.3616\n",
            "Epoch 60/100\n",
            "421/421 [==============================] - 5s 11ms/step - loss: 0.1023 - accuracy: 0.9747 - val_loss: 3.1588 - val_accuracy: 0.3887\n",
            "Epoch 61/100\n",
            "421/421 [==============================] - 5s 11ms/step - loss: 0.0933 - accuracy: 0.9756 - val_loss: 2.7761 - val_accuracy: 0.3788\n",
            "Epoch 62/100\n",
            "421/421 [==============================] - 5s 12ms/step - loss: 0.0757 - accuracy: 0.9810 - val_loss: 3.1820 - val_accuracy: 0.3481\n",
            "Epoch 63/100\n",
            "421/421 [==============================] - 5s 12ms/step - loss: 0.0823 - accuracy: 0.9765 - val_loss: 5.0307 - val_accuracy: 0.2952\n",
            "Epoch 64/100\n",
            "421/421 [==============================] - 5s 12ms/step - loss: 0.1045 - accuracy: 0.9706 - val_loss: 3.3116 - val_accuracy: 0.3198\n",
            "Epoch 65/100\n",
            "421/421 [==============================] - 5s 12ms/step - loss: 0.1031 - accuracy: 0.9679 - val_loss: 4.3033 - val_accuracy: 0.3235\n",
            "Epoch 66/100\n",
            "421/421 [==============================] - 5s 11ms/step - loss: 0.0831 - accuracy: 0.9753 - val_loss: 2.8094 - val_accuracy: 0.3813\n",
            "Epoch 67/100\n",
            "421/421 [==============================] - 5s 11ms/step - loss: 0.0755 - accuracy: 0.9801 - val_loss: 3.3362 - val_accuracy: 0.3383\n",
            "Epoch 68/100\n",
            "421/421 [==============================] - 5s 11ms/step - loss: 0.0815 - accuracy: 0.9756 - val_loss: 3.0614 - val_accuracy: 0.3850\n",
            "Epoch 69/100\n",
            "421/421 [==============================] - 5s 11ms/step - loss: 0.0989 - accuracy: 0.9694 - val_loss: 3.5242 - val_accuracy: 0.3272\n",
            "Epoch 70/100\n",
            "421/421 [==============================] - 5s 11ms/step - loss: 0.0935 - accuracy: 0.9712 - val_loss: 3.5694 - val_accuracy: 0.3493\n",
            "Epoch 71/100\n",
            "421/421 [==============================] - 5s 11ms/step - loss: 0.0755 - accuracy: 0.9771 - val_loss: 3.0479 - val_accuracy: 0.3665\n",
            "Epoch 72/100\n",
            "421/421 [==============================] - 5s 11ms/step - loss: 0.0802 - accuracy: 0.9750 - val_loss: 3.9658 - val_accuracy: 0.3419\n",
            "Epoch 73/100\n",
            "421/421 [==============================] - 5s 11ms/step - loss: 0.0825 - accuracy: 0.9762 - val_loss: 3.2162 - val_accuracy: 0.3555\n",
            "Epoch 74/100\n",
            "421/421 [==============================] - 5s 11ms/step - loss: 0.0718 - accuracy: 0.9765 - val_loss: 2.9264 - val_accuracy: 0.3838\n",
            "Epoch 75/100\n",
            "421/421 [==============================] - 5s 11ms/step - loss: 0.0891 - accuracy: 0.9703 - val_loss: 3.7166 - val_accuracy: 0.3407\n",
            "Epoch 76/100\n",
            "421/421 [==============================] - 5s 11ms/step - loss: 0.0727 - accuracy: 0.9774 - val_loss: 3.3845 - val_accuracy: 0.3407\n",
            "Epoch 77/100\n",
            "421/421 [==============================] - 5s 11ms/step - loss: 0.0744 - accuracy: 0.9789 - val_loss: 3.1015 - val_accuracy: 0.3481\n",
            "Epoch 78/100\n",
            "421/421 [==============================] - 5s 11ms/step - loss: 0.0623 - accuracy: 0.9825 - val_loss: 3.2649 - val_accuracy: 0.3592\n",
            "Epoch 79/100\n",
            "421/421 [==============================] - 5s 11ms/step - loss: 0.0756 - accuracy: 0.9747 - val_loss: 4.1145 - val_accuracy: 0.3419\n",
            "Epoch 80/100\n",
            "421/421 [==============================] - 5s 11ms/step - loss: 0.0870 - accuracy: 0.9736 - val_loss: 3.3965 - val_accuracy: 0.3604\n",
            "Epoch 81/100\n",
            "421/421 [==============================] - 5s 11ms/step - loss: 0.0905 - accuracy: 0.9712 - val_loss: 3.2194 - val_accuracy: 0.3419\n",
            "Epoch 82/100\n",
            "421/421 [==============================] - 5s 11ms/step - loss: 0.0697 - accuracy: 0.9783 - val_loss: 3.1953 - val_accuracy: 0.3653\n",
            "Epoch 83/100\n",
            "421/421 [==============================] - 5s 11ms/step - loss: 0.0689 - accuracy: 0.9774 - val_loss: 3.3948 - val_accuracy: 0.3469\n",
            "Epoch 84/100\n",
            "421/421 [==============================] - 5s 11ms/step - loss: 0.0626 - accuracy: 0.9840 - val_loss: 3.0633 - val_accuracy: 0.3641\n",
            "Epoch 85/100\n",
            "421/421 [==============================] - 5s 11ms/step - loss: 0.0816 - accuracy: 0.9780 - val_loss: 3.2244 - val_accuracy: 0.3616\n",
            "Epoch 86/100\n",
            "421/421 [==============================] - 5s 11ms/step - loss: 0.0659 - accuracy: 0.9813 - val_loss: 3.5685 - val_accuracy: 0.3801\n",
            "Epoch 87/100\n",
            "421/421 [==============================] - 5s 11ms/step - loss: 0.0614 - accuracy: 0.9831 - val_loss: 4.4023 - val_accuracy: 0.2755\n",
            "Epoch 88/100\n",
            "421/421 [==============================] - 5s 11ms/step - loss: 0.0709 - accuracy: 0.9771 - val_loss: 3.0884 - val_accuracy: 0.3850\n",
            "Epoch 89/100\n",
            "421/421 [==============================] - 5s 11ms/step - loss: 0.0737 - accuracy: 0.9780 - val_loss: 3.2886 - val_accuracy: 0.3592\n",
            "Epoch 90/100\n",
            "421/421 [==============================] - 5s 11ms/step - loss: 0.0695 - accuracy: 0.9783 - val_loss: 3.5248 - val_accuracy: 0.3678\n",
            "Epoch 91/100\n",
            "421/421 [==============================] - 5s 11ms/step - loss: 0.0582 - accuracy: 0.9840 - val_loss: 3.8408 - val_accuracy: 0.3026\n",
            "Epoch 92/100\n",
            "421/421 [==============================] - 5s 11ms/step - loss: 0.0722 - accuracy: 0.9780 - val_loss: 3.3782 - val_accuracy: 0.3198\n",
            "Epoch 93/100\n",
            "421/421 [==============================] - 5s 11ms/step - loss: 0.0797 - accuracy: 0.9715 - val_loss: 3.2895 - val_accuracy: 0.3247\n",
            "Epoch 94/100\n",
            "421/421 [==============================] - 5s 11ms/step - loss: 0.0684 - accuracy: 0.9771 - val_loss: 3.5964 - val_accuracy: 0.3346\n",
            "Epoch 95/100\n",
            "421/421 [==============================] - 5s 12ms/step - loss: 0.0600 - accuracy: 0.9798 - val_loss: 3.2651 - val_accuracy: 0.3727\n",
            "Epoch 96/100\n",
            "421/421 [==============================] - 5s 11ms/step - loss: 0.0698 - accuracy: 0.9786 - val_loss: 3.5164 - val_accuracy: 0.3641\n",
            "Epoch 97/100\n",
            "421/421 [==============================] - 5s 11ms/step - loss: 0.0676 - accuracy: 0.9798 - val_loss: 3.6356 - val_accuracy: 0.3555\n",
            "Epoch 98/100\n",
            "421/421 [==============================] - 5s 11ms/step - loss: 0.0738 - accuracy: 0.9762 - val_loss: 3.0897 - val_accuracy: 0.3788\n",
            "Epoch 99/100\n",
            "421/421 [==============================] - 5s 11ms/step - loss: 0.0560 - accuracy: 0.9840 - val_loss: 3.5936 - val_accuracy: 0.3407\n",
            "Epoch 100/100\n",
            "421/421 [==============================] - 5s 11ms/step - loss: 0.0504 - accuracy: 0.9854 - val_loss: 3.4823 - val_accuracy: 0.3592\n",
            "102/102 [==============================] - 1s 5ms/step - loss: 3.1588 - accuracy: 0.3887\n",
            "final loss 3.158823251724243, final acc 0.38868388533592224\n",
            "7/7 [==============================] - 0s 31ms/step - loss: 4.0150 - accuracy: 0.4231\n",
            "test loss 4.015048027038574, test acc 0.42307692766189575\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zxTkqwrnL1Dp",
        "outputId": "983cba2c-1c97-49bc-efc2-7155c23b6b98"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "source": [
        "pred_actuals = []\r\n",
        "for class_name in range(1,11):\r\n",
        "    i = 0\r\n",
        "    while i < 5:\r\n",
        "        pred_actuals.append(class_name)\r\n",
        "        i += 1"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "source": [
        "#view predictions\r\n",
        "\r\n",
        "pred_classes = model.predict(test).argmax(axis=-1) + 1\r\n",
        "\r\n",
        "preds_df = pd.DataFrame(list(zip(pred_actuals, pred_classes)), columns=['actual', 'predicted'])\r\n",
        "preds_df['is_correct'] = preds_df.apply(lambda x: x['actual'] == x['predicted'], axis=1)"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qr1LuAw0P3AT",
        "outputId": "a4bfea92-f58f-4084-d7d8-6e532c949738"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "source": [
        "preds_df.groupby('actual').mean()['is_correct']"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "actual\n",
              "1     1.0\n",
              "2     0.4\n",
              "3     0.2\n",
              "4     0.4\n",
              "5     0.6\n",
              "6     0.2\n",
              "7     0.4\n",
              "8     0.6\n",
              "9     0.4\n",
              "10    0.6\n",
              "Name: is_correct, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [],
      "outputs": [],
      "metadata": {}
    }
  ]
}