{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<a href=\"https://colab.research.google.com/github/EricHeidbreder/data-centric-ai/blob/eric_h/data_centric_ai_comp_copy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ],
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "source": [
        "\r\n",
        "import requests\r\n",
        "import tarfile\r\n",
        "import io\r\n",
        "import numpy as np\r\n",
        "from PIL import Image, ImageTk\r\n",
        "from matplotlib import pyplot as plt\r\n",
        "import pandas as pd\r\n",
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\r\n",
        "from tensorflow.python.keras.preprocessing import dataset_utils\r\n",
        "import os\r\n",
        "import tensorflow as tf\r\n",
        "from tensorflow import keras\r\n",
        "import json\r\n",
        "import sys\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "# from google.colab.patches import cv2_imshow\r\n",
        "\r\n",
        "import shutil\r\n",
        "import random"
      ],
      "outputs": [],
      "metadata": {
        "id": "L965aAYLKcWv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "source": [
        "# Give you a fresh start on preprocessed data\r\n",
        "shutil.rmtree('./data_preprocessed', ignore_errors=True)\r\n",
        "\r\n",
        "# Building the preprocessing folder structure\r\n",
        "os.mkdir('./data_preprocessed')\r\n",
        "os.mkdir('./data_preprocessed/train')\r\n",
        "os.mkdir('./data_preprocessed/val')\r\n",
        "for num in ['i', 'ii', 'iii', 'iv', 'v', 'vi', 'vii', 'viii', 'ix', 'x']:\r\n",
        "    os.mkdir(f'./data_preprocessed/train/{num}')\r\n",
        "    os.mkdir(f'./data_preprocessed/val/{num}')"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "source": [
        "# get the test data into its own folder\r\n",
        "\r\n",
        "test_path = './data_preprocessed/test'\r\n",
        "\r\n",
        "tar_file = tarfile.open('./label_book.tar.gz')\r\n",
        "tar_file.extractall(test_path)\r\n",
        "tar_file.close()\r\n",
        "\r\n",
        "orig_base_path = os.path.join(test_path, 'label_book')\r\n",
        "for folder in os.listdir(orig_base_path):\r\n",
        "    if folder != '.DS_Store':\r\n",
        "        orig_path = os.path.join(orig_base_path, folder)\r\n",
        "        new_path = test_path\r\n",
        "        shutil.move(orig_path, new_path)\r\n",
        "\r\n",
        "shutil.rmtree(orig_base_path)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "source": [
        "train_datagen = ImageDataGenerator(rotation_range=15,\r\n",
        "                                   width_shift_range=0.2,\r\n",
        "                                   height_shift_range=0.2,\r\n",
        "                                   rescale=1/255,\r\n",
        "                                #    shear_range=0.2,\r\n",
        "                                   zoom_range=0.2,\r\n",
        "                                   horizontal_flip=False)\r\n",
        "\r\n",
        "valid_datagen = ImageDataGenerator(rotation_range=20,\r\n",
        "                                   width_shift_range=0.2,\r\n",
        "                                   height_shift_range=0.2,\r\n",
        "                                   rescale=1/255,\r\n",
        "                                 #   shear_range=0.2,\r\n",
        "                                   zoom_range=0.2,\r\n",
        "                                   horizontal_flip=False)"
      ],
      "outputs": [],
      "metadata": {
        "id": "yGI7F9v5LZyh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "source": [
        "# batch_size = len(os.listdir('.\\\\data_sorted\\\\train\\\\ii'))"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GOLzY53-WT9n",
        "outputId": "9f5d4af2-2b7c-40ae-c325-64060404f9d8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "source": [
        "data_sorted_path = '.\\\\data_sorted_copy'\r\n",
        "class_folders = os.listdir(data_sorted_path)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "source": [
        "for folder in class_folders:\r\n",
        "  # Don't do this in the test folder\r\n",
        "  if folder not in [\r\n",
        "    'test',\r\n",
        "    # 'train',\r\n",
        "    '.DS_Store',\r\n",
        "    # TODO: remove val after subgroups are added to that folder\r\n",
        "    # 'val'\r\n",
        "  ]:\r\n",
        "    class_folders = os.listdir(os.path.join(data_sorted_path, folder))\r\n",
        "  else:\r\n",
        "    continue\r\n",
        "\r\n",
        "  # Iterates through the subfolders in each class. \r\n",
        "  # Makes sure there are an equal number of items from each subgroup within the classes by randomly sampling the smaller subgroups\r\n",
        "  for class_folder in class_folders:\r\n",
        "    \r\n",
        "    # Gather initial information about the class path and the number of subgroups\r\n",
        "    if class_folder not in ['.DS_Store', 'junk_vals']:\r\n",
        "    # if class_folder == 'i':\r\n",
        "      class_path = os.path.join(data_sorted_path, folder, class_folder)\r\n",
        "      class_subgroups = os.listdir(class_path)\r\n",
        "      max_subgroup_len = 0\r\n",
        "\r\n",
        "      # Need to get the max number of files in a subgroup folder, so we can get them all to match later\r\n",
        "      for class_folder_subgroup in class_subgroups:\r\n",
        "        max_subgroup_len = max(len(os.listdir(os.path.join(data_sorted_path, folder, class_folder, class_folder_subgroup))), max_subgroup_len)\r\n",
        "\r\n",
        "      # Get the subgroup path (example i_lowercase, i_ruled, etc.)\r\n",
        "      for class_folder_subgroup in class_subgroups:\r\n",
        "        class_subgroup_path = os.path.join(data_sorted_path, folder, class_folder, class_folder_subgroup)\r\n",
        "\r\n",
        "        # If the subgroup isn't the max length, determine how many copies we need to make to get it to match\r\n",
        "        if len(os.listdir(class_subgroup_path)) < max_subgroup_len:\r\n",
        "          subgroup_images = os.listdir(class_subgroup_path)\r\n",
        "          num_subgroup_images = len(subgroup_images)\r\n",
        "          num_copies_to_make = max_subgroup_len - num_subgroup_images\r\n",
        "\r\n",
        "          # Make the copies using random sampling of the existing images\r\n",
        "          for i in range(num_copies_to_make):\r\n",
        "            random_image = subgroup_images[random.randint(0, num_subgroup_images - 1)]\r\n",
        "            shutil.copyfile(os.path.join(class_subgroup_path, random_image), class_subgroup_path+f'/copy_{i}_{random_image}')\r\n",
        "\r\n",
        "    else:\r\n",
        "        continue"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "source": [
        "class_names=[\"i\", \"ii\", \"iii\", \"iv\", \"v\", \"vi\", \"vii\", \"viii\", \"ix\", \"x\"]\r\n",
        "batch_size=600\r\n",
        "\r\n",
        "for class_name in class_names:\r\n",
        "  train_generator = train_datagen.flow_from_directory(\r\n",
        "    './data_sorted_copy/train',\r\n",
        "    target_size=(32,32),\r\n",
        "    batch_size=batch_size,\r\n",
        "    classes=[class_name],\r\n",
        "    save_to_dir='./data_preprocessed/train/'+class_name,\r\n",
        "    save_prefix='aug',\r\n",
        "    shuffle=True\r\n",
        "  )\r\n",
        "  batch = next(train_generator)\r\n",
        " \r\n",
        "for class_name in class_names:\r\n",
        "  # batch_size = len([f for f in os.listdir('./data_sorted_copy/val/'+ class_name) if os.path.isfile(os.path.join('./data_sorted_copy/val/' + class_name, f))])\r\n",
        "  batch_size=batch_size\r\n",
        "  validation_generator = train_datagen.flow_from_directory(\r\n",
        "        './data_sorted_copy/val',\r\n",
        "        target_size=(32, 32),\r\n",
        "        class_mode='categorical',\r\n",
        "        classes=[class_name],\r\n",
        "        batch_size=batch_size,\r\n",
        "        shuffle=True,\r\n",
        "        save_to_dir='./data_preprocessed/val/'+class_name,\r\n",
        "        save_prefix='aug')  \r\n",
        "  batch = next(validation_generator)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 513 images belonging to 1 classes.\n",
            "Found 270 images belonging to 1 classes.\n",
            "Found 258 images belonging to 1 classes.\n",
            "Found 549 images belonging to 1 classes.\n",
            "Found 339 images belonging to 1 classes.\n",
            "Found 210 images belonging to 1 classes.\n",
            "Found 256 images belonging to 1 classes.\n",
            "Found 375 images belonging to 1 classes.\n",
            "Found 312 images belonging to 1 classes.\n",
            "Found 345 images belonging to 1 classes.\n",
            "Found 123 images belonging to 1 classes.\n",
            "Found 90 images belonging to 1 classes.\n",
            "Found 123 images belonging to 1 classes.\n",
            "Found 132 images belonging to 1 classes.\n",
            "Found 130 images belonging to 1 classes.\n",
            "Found 90 images belonging to 1 classes.\n",
            "Found 98 images belonging to 1 classes.\n",
            "Found 159 images belonging to 1 classes.\n",
            "Found 110 images belonging to 1 classes.\n",
            "Found 138 images belonging to 1 classes.\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WWOantahLe7c",
        "outputId": "7b536468-8196-4358-f23d-5a9cee06f134"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "source": [
        "directory = \"./data_preprocessed\"\r\n",
        "user_data = directory + \"/train\"\r\n",
        "valid_data = directory + \"/val\"\r\n",
        "test_data = directory + \"/test\" # this can be the label book, or any other test set you create\r\n",
        "\r\n",
        "### DO NOT MODIFY BELOW THIS LINE, THIS IS THE FIXED MODEL ###\r\n",
        "batch_size = 8\r\n",
        "tf.random.set_seed(123)\r\n",
        "\r\n",
        "\r\n",
        "if __name__ == \"__main__\":\r\n",
        "    train = tf.keras.preprocessing.image_dataset_from_directory(\r\n",
        "        user_data,# + '/train',\r\n",
        "        labels=\"inferred\",\r\n",
        "        label_mode=\"categorical\",\r\n",
        "        class_names=[\"i\", \"ii\", \"iii\", \"iv\", \"v\", \"vi\", \"vii\", \"viii\", \"ix\", \"x\"],\r\n",
        "        shuffle=True,\r\n",
        "        seed=123,\r\n",
        "        batch_size=batch_size,\r\n",
        "        image_size=(32, 32),\r\n",
        "    )\r\n",
        "\r\n",
        "    valid = tf.keras.preprocessing.image_dataset_from_directory(\r\n",
        "        valid_data,# + '/val',\r\n",
        "        labels=\"inferred\",\r\n",
        "        label_mode=\"categorical\",\r\n",
        "        class_names=[\"i\", \"ii\", \"iii\", \"iv\", \"v\", \"vi\", \"vii\", \"viii\", \"ix\", \"x\"],\r\n",
        "        shuffle=True,\r\n",
        "        seed=123,\r\n",
        "        batch_size=batch_size,\r\n",
        "        image_size=(32, 32),\r\n",
        "    )\r\n",
        "\r\n",
        "    total_length = ((train.cardinality() + valid.cardinality()) * batch_size).numpy()\r\n",
        "    if total_length > 10_000:\r\n",
        "        print(f\"Dataset size larger than 10,000. Got {total_length} examples\")\r\n",
        "        sys.exit()\r\n",
        "\r\n",
        "    test = tf.keras.preprocessing.image_dataset_from_directory(\r\n",
        "        test_data,\r\n",
        "        labels=\"inferred\",\r\n",
        "        label_mode=\"categorical\",\r\n",
        "        class_names=[\"i\", \"ii\", \"iii\", \"iv\", \"v\", \"vi\", \"vii\", \"viii\", \"ix\", \"x\"],\r\n",
        "        shuffle=False,\r\n",
        "        seed=123,\r\n",
        "        batch_size=batch_size,\r\n",
        "        image_size=(32, 32),\r\n",
        "    )\r\n",
        "\r\n",
        "    base_model = tf.keras.applications.ResNet50(\r\n",
        "        input_shape=(32, 32, 3),\r\n",
        "        include_top=False,\r\n",
        "        weights=None,\r\n",
        "    )\r\n",
        "    base_model = tf.keras.Model(\r\n",
        "        base_model.inputs, outputs=[base_model.get_layer(\"conv2_block3_out\").output]\r\n",
        "    )\r\n",
        "\r\n",
        "    inputs = tf.keras.Input(shape=(32, 32, 3))\r\n",
        "    x = tf.keras.applications.resnet.preprocess_input(inputs)\r\n",
        "    x = base_model(x)\r\n",
        "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\r\n",
        "    x = tf.keras.layers.Dense(10)(x)\r\n",
        "    model = tf.keras.Model(inputs, x)\r\n",
        "\r\n",
        "    model.compile(\r\n",
        "        optimizer=tf.keras.optimizers.Adam(lr=0.0001),\r\n",
        "        loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\r\n",
        "        metrics=[\"accuracy\"],\r\n",
        "    )\r\n",
        "    model.summary()\r\n",
        "    loss_0, acc_0 = model.evaluate(valid)\r\n",
        "    print(f\"loss {loss_0}, acc {acc_0}\")\r\n",
        "\r\n",
        "    checkpoint = tf.keras.callbacks.ModelCheckpoint(\r\n",
        "        \"best_model\",\r\n",
        "        monitor=\"val_accuracy\",\r\n",
        "        mode=\"max\",\r\n",
        "        save_best_only=True,\r\n",
        "        save_weights_only=True,\r\n",
        "    )\r\n",
        "\r\n",
        "    history = model.fit(\r\n",
        "        train,\r\n",
        "        validation_data=valid,\r\n",
        "        epochs=100,\r\n",
        "        callbacks=[checkpoint],\r\n",
        "    )\r\n",
        "\r\n",
        "    model.load_weights(\"best_model\")\r\n",
        "\r\n",
        "    loss, acc = model.evaluate(valid)\r\n",
        "    print(f\"final loss {loss}, final acc {acc}\")\r\n",
        "\r\n",
        "    test_loss, test_acc = model.evaluate(test)\r\n",
        "    print(f\"test loss {test_loss}, test acc {test_acc}\")\r\n",
        "\r\n",
        "   "
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3427 files belonging to 10 classes.\n",
            "Found 1193 files belonging to 10 classes.\n",
            "Found 52 files belonging to 10 classes.\n",
            "Model: \"model_13\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_14 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
            "_________________________________________________________________\n",
            "tf.__operators__.getitem_6 ( (None, 32, 32, 3)         0         \n",
            "_________________________________________________________________\n",
            "tf.nn.bias_add_6 (TFOpLambda (None, 32, 32, 3)         0         \n",
            "_________________________________________________________________\n",
            "model_12 (Functional)        (None, 8, 8, 256)         229760    \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_6 ( (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 10)                2570      \n",
            "=================================================================\n",
            "Total params: 232,330\n",
            "Trainable params: 229,386\n",
            "Non-trainable params: 2,944\n",
            "_________________________________________________________________\n",
            "150/150 [==============================] - 5s 28ms/step - loss: 32.6704 - accuracy: 0.0882\n",
            "loss 33.083492279052734, acc 0.09220452606678009\n",
            "Epoch 1/100\n",
            "429/429 [==============================] - 16s 35ms/step - loss: 1.9115 - accuracy: 0.3414 - val_loss: 1.9167 - val_accuracy: 0.3177\n",
            "Epoch 2/100\n",
            "429/429 [==============================] - 5s 12ms/step - loss: 1.4282 - accuracy: 0.5127 - val_loss: 1.6009 - val_accuracy: 0.4099\n",
            "Epoch 3/100\n",
            "429/429 [==============================] - 5s 12ms/step - loss: 1.1872 - accuracy: 0.6049 - val_loss: 1.3857 - val_accuracy: 0.5423\n",
            "Epoch 4/100\n",
            "429/429 [==============================] - 5s 12ms/step - loss: 1.0122 - accuracy: 0.6612 - val_loss: 1.2712 - val_accuracy: 0.5549\n",
            "Epoch 5/100\n",
            "429/429 [==============================] - 5s 12ms/step - loss: 0.8669 - accuracy: 0.7172 - val_loss: 1.1674 - val_accuracy: 0.6085\n",
            "Epoch 6/100\n",
            "429/429 [==============================] - 5s 12ms/step - loss: 0.7563 - accuracy: 0.7537 - val_loss: 1.0725 - val_accuracy: 0.6329\n",
            "Epoch 7/100\n",
            "429/429 [==============================] - 5s 12ms/step - loss: 0.6728 - accuracy: 0.7823 - val_loss: 0.9919 - val_accuracy: 0.6597\n",
            "Epoch 8/100\n",
            "429/429 [==============================] - 5s 12ms/step - loss: 0.5911 - accuracy: 0.8188 - val_loss: 1.0863 - val_accuracy: 0.6178\n",
            "Epoch 9/100\n",
            "429/429 [==============================] - 5s 12ms/step - loss: 0.5135 - accuracy: 0.8436 - val_loss: 1.0580 - val_accuracy: 0.6295\n",
            "Epoch 10/100\n",
            "429/429 [==============================] - 5s 12ms/step - loss: 0.4526 - accuracy: 0.8594 - val_loss: 1.1467 - val_accuracy: 0.5951\n",
            "Epoch 11/100\n",
            "429/429 [==============================] - 5s 12ms/step - loss: 0.4034 - accuracy: 0.8766 - val_loss: 1.3662 - val_accuracy: 0.5901\n",
            "Epoch 12/100\n",
            "429/429 [==============================] - 5s 12ms/step - loss: 0.3487 - accuracy: 0.9011 - val_loss: 1.2496 - val_accuracy: 0.5960\n",
            "Epoch 13/100\n",
            "429/429 [==============================] - 5s 12ms/step - loss: 0.3155 - accuracy: 0.9145 - val_loss: 1.4028 - val_accuracy: 0.5381\n",
            "Epoch 14/100\n",
            "429/429 [==============================] - 5s 12ms/step - loss: 0.2852 - accuracy: 0.9177 - val_loss: 1.5975 - val_accuracy: 0.5549\n",
            "Epoch 15/100\n",
            "429/429 [==============================] - 5s 12ms/step - loss: 0.2270 - accuracy: 0.9454 - val_loss: 1.2726 - val_accuracy: 0.6010\n",
            "Epoch 16/100\n",
            "429/429 [==============================] - 5s 12ms/step - loss: 0.2248 - accuracy: 0.9364 - val_loss: 1.1910 - val_accuracy: 0.6295\n",
            "Epoch 17/100\n",
            "429/429 [==============================] - 5s 12ms/step - loss: 0.1859 - accuracy: 0.9516 - val_loss: 1.2671 - val_accuracy: 0.6220\n",
            "Epoch 18/100\n",
            "429/429 [==============================] - 5s 12ms/step - loss: 0.1692 - accuracy: 0.9580 - val_loss: 1.1844 - val_accuracy: 0.6429\n",
            "Epoch 19/100\n",
            "429/429 [==============================] - 5s 12ms/step - loss: 0.1555 - accuracy: 0.9597 - val_loss: 1.6010 - val_accuracy: 0.5641\n",
            "Epoch 20/100\n",
            "429/429 [==============================] - 5s 12ms/step - loss: 0.1653 - accuracy: 0.9583 - val_loss: 1.2360 - val_accuracy: 0.6245\n",
            "Epoch 21/100\n",
            "429/429 [==============================] - 5s 12ms/step - loss: 0.1331 - accuracy: 0.9708 - val_loss: 1.5563 - val_accuracy: 0.5817\n",
            "Epoch 22/100\n",
            "429/429 [==============================] - 5s 12ms/step - loss: 0.1203 - accuracy: 0.9705 - val_loss: 1.2401 - val_accuracy: 0.6429\n",
            "Epoch 23/100\n",
            "429/429 [==============================] - 5s 12ms/step - loss: 0.1162 - accuracy: 0.9679 - val_loss: 1.2069 - val_accuracy: 0.6303\n",
            "Epoch 24/100\n",
            "429/429 [==============================] - 5s 12ms/step - loss: 0.1044 - accuracy: 0.9746 - val_loss: 1.6221 - val_accuracy: 0.5884\n",
            "Epoch 25/100\n",
            "429/429 [==============================] - 5s 12ms/step - loss: 0.1052 - accuracy: 0.9752 - val_loss: 2.0173 - val_accuracy: 0.4912\n",
            "Epoch 26/100\n",
            "429/429 [==============================] - 5s 12ms/step - loss: 0.0888 - accuracy: 0.9804 - val_loss: 1.2482 - val_accuracy: 0.6186\n",
            "Epoch 27/100\n",
            "429/429 [==============================] - 5s 12ms/step - loss: 0.0917 - accuracy: 0.9769 - val_loss: 2.6880 - val_accuracy: 0.4367\n",
            "Epoch 28/100\n",
            "429/429 [==============================] - 5s 12ms/step - loss: 0.0971 - accuracy: 0.9761 - val_loss: 1.3552 - val_accuracy: 0.6396\n",
            "Epoch 29/100\n",
            "429/429 [==============================] - 5s 12ms/step - loss: 0.0789 - accuracy: 0.9831 - val_loss: 1.4078 - val_accuracy: 0.6295\n",
            "Epoch 30/100\n",
            "429/429 [==============================] - 5s 12ms/step - loss: 0.0798 - accuracy: 0.9810 - val_loss: 1.7396 - val_accuracy: 0.5708\n",
            "Epoch 31/100\n",
            "429/429 [==============================] - 5s 12ms/step - loss: 0.0745 - accuracy: 0.9807 - val_loss: 1.4747 - val_accuracy: 0.6186\n",
            "Epoch 32/100\n",
            "429/429 [==============================] - 5s 12ms/step - loss: 0.0585 - accuracy: 0.9848 - val_loss: 1.5136 - val_accuracy: 0.5977\n",
            "Epoch 33/100\n",
            "429/429 [==============================] - 5s 12ms/step - loss: 0.0763 - accuracy: 0.9784 - val_loss: 1.9215 - val_accuracy: 0.5742\n",
            "Epoch 34/100\n",
            "429/429 [==============================] - 5s 12ms/step - loss: 0.0582 - accuracy: 0.9848 - val_loss: 1.4825 - val_accuracy: 0.6010\n",
            "Epoch 35/100\n",
            "429/429 [==============================] - 5s 12ms/step - loss: 0.0578 - accuracy: 0.9869 - val_loss: 1.4176 - val_accuracy: 0.6295\n",
            "Epoch 36/100\n",
            "429/429 [==============================] - 5s 12ms/step - loss: 0.0783 - accuracy: 0.9810 - val_loss: 1.6844 - val_accuracy: 0.6085\n",
            "Epoch 37/100\n",
            "429/429 [==============================] - 5s 12ms/step - loss: 0.0530 - accuracy: 0.9875 - val_loss: 1.8064 - val_accuracy: 0.5708\n",
            "Epoch 38/100\n",
            "429/429 [==============================] - 5s 12ms/step - loss: 0.0402 - accuracy: 0.9898 - val_loss: 1.4192 - val_accuracy: 0.6547\n",
            "Epoch 39/100\n",
            "429/429 [==============================] - 5s 12ms/step - loss: 0.0521 - accuracy: 0.9866 - val_loss: 1.7617 - val_accuracy: 0.6035\n",
            "Epoch 40/100\n",
            "429/429 [==============================] - 5s 12ms/step - loss: 0.0597 - accuracy: 0.9840 - val_loss: 2.1324 - val_accuracy: 0.5557\n",
            "Epoch 41/100\n",
            "429/429 [==============================] - 5s 12ms/step - loss: 0.0574 - accuracy: 0.9857 - val_loss: 1.4090 - val_accuracy: 0.6161\n",
            "Epoch 42/100\n",
            "429/429 [==============================] - 5s 12ms/step - loss: 0.0453 - accuracy: 0.9898 - val_loss: 1.4744 - val_accuracy: 0.6287\n",
            "Epoch 43/100\n",
            "429/429 [==============================] - 5s 12ms/step - loss: 0.0526 - accuracy: 0.9848 - val_loss: 1.2546 - val_accuracy: 0.6706\n",
            "Epoch 44/100\n",
            "429/429 [==============================] - 5s 12ms/step - loss: 0.0577 - accuracy: 0.9848 - val_loss: 1.4119 - val_accuracy: 0.6614\n",
            "Epoch 45/100\n",
            "429/429 [==============================] - 5s 12ms/step - loss: 0.0655 - accuracy: 0.9799 - val_loss: 1.3367 - val_accuracy: 0.6438\n",
            "Epoch 46/100\n",
            "429/429 [==============================] - 5s 12ms/step - loss: 0.0441 - accuracy: 0.9904 - val_loss: 1.6392 - val_accuracy: 0.6194\n",
            "Epoch 47/100\n",
            "429/429 [==============================] - 5s 12ms/step - loss: 0.0392 - accuracy: 0.9901 - val_loss: 1.6287 - val_accuracy: 0.6052\n",
            "Epoch 48/100\n",
            "429/429 [==============================] - 5s 12ms/step - loss: 0.0371 - accuracy: 0.9901 - val_loss: 1.4654 - val_accuracy: 0.6362\n",
            "Epoch 49/100\n",
            "429/429 [==============================] - 5s 12ms/step - loss: 0.0397 - accuracy: 0.9907 - val_loss: 1.4510 - val_accuracy: 0.6446\n",
            "Epoch 50/100\n",
            "429/429 [==============================] - 5s 12ms/step - loss: 0.0467 - accuracy: 0.9863 - val_loss: 2.0504 - val_accuracy: 0.5457\n",
            "Epoch 51/100\n",
            "429/429 [==============================] - 6s 13ms/step - loss: 0.0464 - accuracy: 0.9872 - val_loss: 1.4492 - val_accuracy: 0.6630\n",
            "Epoch 52/100\n",
            "429/429 [==============================] - 6s 13ms/step - loss: 0.0468 - accuracy: 0.9877 - val_loss: 1.6477 - val_accuracy: 0.6236\n",
            "Epoch 53/100\n",
            "429/429 [==============================] - 5s 13ms/step - loss: 0.0285 - accuracy: 0.9953 - val_loss: 1.3699 - val_accuracy: 0.6655\n",
            "Epoch 54/100\n",
            "429/429 [==============================] - 6s 13ms/step - loss: 0.0475 - accuracy: 0.9875 - val_loss: 1.3005 - val_accuracy: 0.6857\n",
            "Epoch 55/100\n",
            "429/429 [==============================] - 6s 13ms/step - loss: 0.0468 - accuracy: 0.9877 - val_loss: 1.3163 - val_accuracy: 0.6647\n",
            "Epoch 56/100\n",
            "429/429 [==============================] - 6s 13ms/step - loss: 0.0352 - accuracy: 0.9901 - val_loss: 1.9732 - val_accuracy: 0.5842\n",
            "Epoch 57/100\n",
            "429/429 [==============================] - 6s 13ms/step - loss: 0.0348 - accuracy: 0.9904 - val_loss: 1.6045 - val_accuracy: 0.6320\n",
            "Epoch 58/100\n",
            "429/429 [==============================] - 5s 13ms/step - loss: 0.0338 - accuracy: 0.9904 - val_loss: 2.0864 - val_accuracy: 0.5683\n",
            "Epoch 59/100\n",
            "429/429 [==============================] - 5s 13ms/step - loss: 0.0351 - accuracy: 0.9918 - val_loss: 1.5024 - val_accuracy: 0.6479\n",
            "Epoch 60/100\n",
            "429/429 [==============================] - 5s 12ms/step - loss: 0.0237 - accuracy: 0.9953 - val_loss: 1.6746 - val_accuracy: 0.6253\n",
            "Epoch 61/100\n",
            "429/429 [==============================] - 5s 13ms/step - loss: 0.0333 - accuracy: 0.9910 - val_loss: 2.3199 - val_accuracy: 0.5549\n",
            "Epoch 62/100\n",
            "429/429 [==============================] - 5s 12ms/step - loss: 0.0266 - accuracy: 0.9953 - val_loss: 1.3784 - val_accuracy: 0.6588\n",
            "Epoch 63/100\n",
            "429/429 [==============================] - 5s 12ms/step - loss: 0.0217 - accuracy: 0.9947 - val_loss: 1.8769 - val_accuracy: 0.5859\n",
            "Epoch 64/100\n",
            "429/429 [==============================] - 5s 13ms/step - loss: 0.0364 - accuracy: 0.9895 - val_loss: 1.8535 - val_accuracy: 0.6027\n",
            "Epoch 65/100\n",
            "429/429 [==============================] - 5s 12ms/step - loss: 0.0408 - accuracy: 0.9872 - val_loss: 1.5839 - val_accuracy: 0.6169\n",
            "Epoch 66/100\n",
            "429/429 [==============================] - 5s 13ms/step - loss: 0.0356 - accuracy: 0.9895 - val_loss: 2.4405 - val_accuracy: 0.5407\n",
            "Epoch 67/100\n",
            "429/429 [==============================] - 6s 13ms/step - loss: 0.0490 - accuracy: 0.9857 - val_loss: 1.5539 - val_accuracy: 0.6253\n",
            "Epoch 68/100\n",
            "429/429 [==============================] - 6s 13ms/step - loss: 0.0194 - accuracy: 0.9959 - val_loss: 1.3906 - val_accuracy: 0.6790\n",
            "Epoch 69/100\n",
            "429/429 [==============================] - 6s 13ms/step - loss: 0.0200 - accuracy: 0.9968 - val_loss: 1.4423 - val_accuracy: 0.6672\n",
            "Epoch 70/100\n",
            "429/429 [==============================] - 6s 13ms/step - loss: 0.0215 - accuracy: 0.9942 - val_loss: 1.7625 - val_accuracy: 0.6236\n",
            "Epoch 71/100\n",
            "429/429 [==============================] - 6s 13ms/step - loss: 0.0351 - accuracy: 0.9889 - val_loss: 1.4798 - val_accuracy: 0.6547\n",
            "Epoch 72/100\n",
            "429/429 [==============================] - 5s 13ms/step - loss: 0.0303 - accuracy: 0.9915 - val_loss: 1.6634 - val_accuracy: 0.6496\n",
            "Epoch 73/100\n",
            "429/429 [==============================] - 6s 13ms/step - loss: 0.0353 - accuracy: 0.9904 - val_loss: 2.2320 - val_accuracy: 0.5583\n",
            "Epoch 74/100\n",
            "429/429 [==============================] - 6s 13ms/step - loss: 0.0267 - accuracy: 0.9933 - val_loss: 1.5432 - val_accuracy: 0.6387\n",
            "Epoch 75/100\n",
            "429/429 [==============================] - 6s 13ms/step - loss: 0.0363 - accuracy: 0.9901 - val_loss: 1.5587 - val_accuracy: 0.6496\n",
            "Epoch 76/100\n",
            "429/429 [==============================] - 6s 13ms/step - loss: 0.0245 - accuracy: 0.9936 - val_loss: 1.4147 - val_accuracy: 0.6614\n",
            "Epoch 77/100\n",
            "429/429 [==============================] - 5s 12ms/step - loss: 0.0231 - accuracy: 0.9930 - val_loss: 1.5386 - val_accuracy: 0.6547\n",
            "Epoch 78/100\n",
            "429/429 [==============================] - 5s 12ms/step - loss: 0.0287 - accuracy: 0.9924 - val_loss: 1.3324 - val_accuracy: 0.6932\n",
            "Epoch 79/100\n",
            "429/429 [==============================] - 5s 13ms/step - loss: 0.0186 - accuracy: 0.9962 - val_loss: 1.3008 - val_accuracy: 0.6781\n",
            "Epoch 80/100\n",
            "429/429 [==============================] - 5s 12ms/step - loss: 0.0201 - accuracy: 0.9953 - val_loss: 1.3978 - val_accuracy: 0.6555\n",
            "Epoch 81/100\n",
            "429/429 [==============================] - 5s 12ms/step - loss: 0.0273 - accuracy: 0.9927 - val_loss: 1.7720 - val_accuracy: 0.6027\n",
            "Epoch 82/100\n",
            "429/429 [==============================] - 5s 12ms/step - loss: 0.0269 - accuracy: 0.9921 - val_loss: 1.7118 - val_accuracy: 0.6463\n",
            "Epoch 83/100\n",
            "429/429 [==============================] - 5s 12ms/step - loss: 0.0288 - accuracy: 0.9907 - val_loss: 1.8978 - val_accuracy: 0.5993\n",
            "Epoch 84/100\n",
            "429/429 [==============================] - 5s 12ms/step - loss: 0.0252 - accuracy: 0.9945 - val_loss: 1.5487 - val_accuracy: 0.6454\n",
            "Epoch 85/100\n",
            "429/429 [==============================] - 5s 12ms/step - loss: 0.0188 - accuracy: 0.9962 - val_loss: 1.5054 - val_accuracy: 0.6412\n",
            "Epoch 86/100\n",
            "429/429 [==============================] - 5s 13ms/step - loss: 0.0336 - accuracy: 0.9889 - val_loss: 2.1988 - val_accuracy: 0.5859\n",
            "Epoch 87/100\n",
            "429/429 [==============================] - 5s 12ms/step - loss: 0.0270 - accuracy: 0.9933 - val_loss: 1.6028 - val_accuracy: 0.6479\n",
            "Epoch 88/100\n",
            "429/429 [==============================] - 5s 12ms/step - loss: 0.0275 - accuracy: 0.9918 - val_loss: 1.7194 - val_accuracy: 0.6287\n",
            "Epoch 89/100\n",
            "429/429 [==============================] - 5s 12ms/step - loss: 0.0248 - accuracy: 0.9930 - val_loss: 1.5539 - val_accuracy: 0.6446\n",
            "Epoch 90/100\n",
            "429/429 [==============================] - 5s 12ms/step - loss: 0.0123 - accuracy: 0.9980 - val_loss: 1.4495 - val_accuracy: 0.6915\n",
            "Epoch 91/100\n",
            "429/429 [==============================] - 5s 12ms/step - loss: 0.0222 - accuracy: 0.9930 - val_loss: 1.5803 - val_accuracy: 0.6496\n",
            "Epoch 92/100\n",
            "429/429 [==============================] - 6s 13ms/step - loss: 0.0271 - accuracy: 0.9921 - val_loss: 1.3568 - val_accuracy: 0.6739\n",
            "Epoch 93/100\n",
            "429/429 [==============================] - 5s 13ms/step - loss: 0.0305 - accuracy: 0.9910 - val_loss: 1.7572 - val_accuracy: 0.6027\n",
            "Epoch 94/100\n",
            "429/429 [==============================] - 5s 12ms/step - loss: 0.0272 - accuracy: 0.9933 - val_loss: 1.3723 - val_accuracy: 0.6798\n",
            "Epoch 95/100\n",
            "429/429 [==============================] - 5s 12ms/step - loss: 0.0101 - accuracy: 0.9974 - val_loss: 1.3986 - val_accuracy: 0.6806\n",
            "Epoch 96/100\n",
            "429/429 [==============================] - 5s 12ms/step - loss: 0.0104 - accuracy: 0.9982 - val_loss: 1.5804 - val_accuracy: 0.6471\n",
            "Epoch 97/100\n",
            "429/429 [==============================] - 5s 12ms/step - loss: 0.0245 - accuracy: 0.9927 - val_loss: 2.0589 - val_accuracy: 0.6069\n",
            "Epoch 98/100\n",
            "429/429 [==============================] - 5s 12ms/step - loss: 0.0264 - accuracy: 0.9915 - val_loss: 1.6944 - val_accuracy: 0.6387\n",
            "Epoch 99/100\n",
            "429/429 [==============================] - 5s 12ms/step - loss: 0.0290 - accuracy: 0.9912 - val_loss: 2.1915 - val_accuracy: 0.5767\n",
            "Epoch 100/100\n",
            "429/429 [==============================] - 5s 12ms/step - loss: 0.0338 - accuracy: 0.9898 - val_loss: 1.7882 - val_accuracy: 0.6312\n",
            "150/150 [==============================] - 1s 6ms/step - loss: 1.3324 - accuracy: 0.6932\n",
            "final loss 1.3323506116867065, final acc 0.6932104229927063\n",
            "7/7 [==============================] - 0s 31ms/step - loss: 2.4660 - accuracy: 0.5769\n",
            "test loss 2.465972423553467, test acc 0.5769230723381042\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zxTkqwrnL1Dp",
        "outputId": "983cba2c-1c97-49bc-efc2-7155c23b6b98"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "source": [
        "pred_actuals = []\r\n",
        "for class_name in range(1,11):\r\n",
        "    i = 0\r\n",
        "    while i < 5:\r\n",
        "        pred_actuals.append(class_name)\r\n",
        "        i += 1"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "source": [
        "#view predictions\r\n",
        "\r\n",
        "pred_classes = model.predict(test).argmax(axis=-1) + 1\r\n",
        "\r\n",
        "preds_df = pd.DataFrame(list(zip(pred_actuals, pred_classes)), columns=['actual', 'predicted'])\r\n",
        "preds_df['is_correct'] = preds_df.apply(lambda x: x['actual'] == x['predicted'], axis=1)"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qr1LuAw0P3AT",
        "outputId": "a4bfea92-f58f-4084-d7d8-6e532c949738"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "source": [
        "preds_df.groupby('actual').mean()['is_correct']"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "actual\n",
              "1     1.0\n",
              "2     0.4\n",
              "3     0.6\n",
              "4     0.6\n",
              "5     0.4\n",
              "6     0.2\n",
              "7     0.2\n",
              "8     0.6\n",
              "9     0.2\n",
              "10    0.4\n",
              "Name: is_correct, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "metadata": {}
    }
  ]
}